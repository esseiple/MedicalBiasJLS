{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Exploring Societal Inequity's Effect on (Model-Perceived) Health Outcomes \n",
    "author: Sophie Seiple, Julia Joy, Lindsey Schweitzer\n",
    "date: '2024-04-18'\n",
    "description: \"Final Project Blog Post\"\n",
    "bibliography: refs.bib\n",
    "format: html\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "For our project, we aim to explore the relationship between diseases and social factors such as sex, race, and town, and how these may reflect societal and enviornmental inequities. Our approach is to identify the most accurate predictive model for our dataset, then use this model to generate risk likelihood scores and evaluate the relationship between different diseases and characteristics indicative of societal inequalities. We will then analyze the implications of these risk factors for inequitable, identity-based risk factors in health outcomes and complications. Our project consists of three documents, one in which we clean our original data, one in which we explore this data visually, and the final one, this one, in which we build and explore our models.\n",
    "\n",
    "Taking the general trends we witness in our data visualization document, we carried out the second half of our project; building a model that predicts risk scores. Comparing the risk scores, we wanted to see whether trends emerged in terms of socioeconomic status (which we measure by the proxy of town of residence), race, gender, and ethnicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values Statement\n",
    "The motivation behind our project was to uncover potential inequities in the manifestations of certain conditions, for example does a persons race or socioeconomic status predispose them to certain conditions more than others. Our goal was to identify potential societal and environmental factors that unjustly, or disproportionately contribute to disparities in health outcomes. Our focus on this project stems from a desire to understand and address societal and evironmental inequities that contribute to disparities in health outcomes, and our personal commitments to promoting equity and social justice in healthcare.\n",
    "\n",
    "The primary potential users of our project would include researchers, policymakers, and public health organizations interested in understanding and addressing health inequities. However, the project's findings and potential implications could also affect the communities we study, especially those that we find experience disparities in health outcomes due to social determinants. \n",
    "\n",
    "If our research were to be taken out of context by researchers and health professionals, and taken to be a study of biological predisposition, and not of the manifestation of social factors, our results may reinforce assumptions about health outcomes by race and ethnicity in the medical field, enforcing harmful stereotypes or leading to further marginalization of certain groups. Additionally, if the data or models have inherent biases, they could perpetuate or amplify existing disparities.\n",
    "\n",
    "With proper usage and implementation though, we hope our results would positively impact public health programs and initiatives that work in preventative measures in the most at-risk communities. With our data, we hope that these measures would more easily idenity communities in which to center efforts and awareness campaigns, by shedding light on health inequities and informing efforts to address them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Material & Methods\n",
    "\n",
    "### Our Data \n",
    "\n",
    "Our project utilizes a synthetic data set created for an Introduction to Biomedical Data Science Textbook, @SyntheaData. The data was created using Synthea, a synthetic patient generator that models the medical history of synthetic patients. Synthea’s mission is “to output high-quality synthetic, realistic but not real, patient data and associated health records covering every aspect of healthcare.” This allowed for much easier access than real patient data, as well as alleviating any privacy concerns that would arise from using real patient data. \n",
    "The link to the data can be found here: https://data.world/siyeh/synthetic-medical-data. \n",
    "\n",
    "Our dataset was originally quite large, with over 200 Million entries. After thorough data cleaning and preprocessing, the data was then transformed to multiple CSV documents, generally with the format of each row representing a different patient with one-hot-encoded values for multiple disease conditions. \n",
    "\n",
    "While using synthetic data has its benefits, it is essential to acknowledge certain inherent limitations. Firstly, despite efforts to create diverse and representative synthetic patients, there may still be discrepancies in representing certain demographic groups or medical conditions accurately. Certain rare or uncommon medical conditions may be underrepresented in the dataset due to the limitations of the modeling and analyses processes. This data is generated to represent patients from Massachusetts, so any generalization of results must proceed with caution. Thus while this synthetic dataset serves as a valuable resource for educational purposes, researchers and practitioners should approach its use with an understanding of its limitations. \n",
    "\n",
    "After cleaning our data, we perfomed exploratory data analysis in order to visualize out datset, the results of which are found in [this extension of our materials and methods section](google.com).\n",
    "\n",
    "\n",
    "### Our Approach \n",
    "\n",
    "Since our original dataset was quite large, a thorough process of data cleaning and preprocess was needed, as well as an evaluation of which parts and features of our data should be actively used as predictors for our models. We subset our data into different CSV files, each entry to a given CSV corresponding to the different type of condition. This allowed for our models to be trained more concisely and efficiently, as well as increasing interpretability of results. [This extension or methods and materials shows our data cleaning pocess in more depth.](google.com)\n",
    "\n",
    "Multiple models were trained for each analysis of a condition group, including a logistic regression model, a decision tree classifier, a random forest classifier, and a support vector machine. These models were then evaluated for best score, using cross-validation, given its performance for a specific condition group. The best model, i.e. the one returning the highest cross-validated accuracy, was chosen as the predictive model for our general risk scores. We then trained this model, which ended up being ??????(WHAT DID IT END UP BEING) on our training dataset, and created predictions for our testing data that represented the probability of each entry being 1 (having a certain condition) or 0 (not having a certain condition). A risk score could then be anything between 0.00 and 1.00, where 0.50 would represent a 50% probability that the given patient has a condition. The models ran on our own personal devices, on the ML-0451 class kernel. \n",
    "\n",
    "### Critical Discussion\n",
    "The goal of our presentation is to analyze the bias present in our healthcare system and the risk of certain groups of different illnesses and health conditions. There are many organizations that might find this type of model useful or interesting. One interested party could be a hospital that wants to allocate resources based on the communities they serve. This could be helpful as they could adapt to real community needs. A similar use case could be if a town is building or allocating healthcare resources and wants to understand the risks of their township or locality. Hopefully, this model could help allow resources to go to the places in which there is great need. However, an important note is that this dataset measures the recorded rates of a hospital setting. This could widely vary from real illness rates, as certain communities are under-treated or under-diagnosed in the US healthcare system.\n",
    "\n",
    "A more harmful use case could be an insurance company that could incorporate this model into their decision to cover individuals or not. Therefore, our model has the risks, if put in the wrong hands, to have a negative impact on already marginalized communities. Seeing as insurance companies are incredibly wealthy, it is likely that this could be a body that would be financing this project. This raises the question of whether this model should be allowed to be employed in decision-making scenarios.\n",
    "\n",
    "We completed this work out of curiosity as part of an educational pursuit. If used for knowledge or understanding of the impact of different illnesses and conditions on identity groups, it can be helpful and informative. However, there is also the risk of further harming groups that have already been historically marginalized in medicine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first extension of our results section is [this document](google.com), in which we run our model and generate the risk scores and comparisons we discuss in further depth here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "talk abt how ethnicities are self-reported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluding Discussion\n",
    "\n",
    "Our project was able to accomplish our goal of analyzing risk rates for various illnesses and conditions for different identities. Due to the large quantity of data we possessed, we were unable to analyze all of the data we had access to to make predictions. Ideally, we would have been able to predict medication use or various observations in addition to specific conditions. Also, if we had access to more data, we could have made more specific predictions- like for asthma instead of general lung ailments. If we had more time, computational resources, and data we would like to extend our study to include healthcare information for different conditions as well as different geographical regions outside of Massachusetts. By amplifying the range of data we include we would be able to come to more concrete conclusions on different risk rates. However, we were able to complete our aspirations for this project by generating risk rates for race, gender, ethnicity, birthplace, and current address for five different ailments.\n",
    "\n",
    "Our results compare to the results of those who have studied similar problems. For example, there is a large quantity of scientific data that shows that people at lower socio-economic status are more likely to get diabetes [Linked Text](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4603875/#:~:text=For%20example%2C%209.0%20%25%20of%20those,%2480%2C000%20per%20year%20had%20diabetes.). Furthermore, race has been strongly connected to material mortality and health. Specifically, black and hispanic women are at much higher risk of issues with pregnancy than their white counterparts [Linked Text](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7290488/). We saw both these trends and more replicated in our model's predictions. Therefore we can conclude that our model is creating predictions that are correlated with real life trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 3 Definitions of Fairness \n",
    "In their paper @FairnessMachineLearning, Barocas, Hardt, and Narayanan outline three relative notions of fairness: the narrow, middle, and broad views. The narrow view of fairness suggests that we should treat similar individuals in the same manner, given how currently similar they are. The broad perspective advocates for structuring society to facilitate similar outcomes for people with comparable abilities and ambitions. The middle-ground stance proposes that we treat different people equally, under the assumption that their apparent dissimilarities stem from factors just as past injustices or misfortunes that should be disregarded. \n",
    "\n",
    "\n",
    "Since our project involves comparing people of different demographic and characteristics, evaluating risk scores and examining fairness, we must look into our project and identify what is fair, as well as what we are choosing to define as fair. \n",
    "\n",
    "Under the narrow view of fairness, since the comparison is between individuals and not directly concerned with the way members of specific groups might be treated, The narrow view only commands that similar people be treated similarly.  In our models, similar people (eg of the same demographic factor being studied such as race, gender, ethnicity…) are being treated similarly in our models. \n",
    "\n",
    "Under the middle view of fairness, since the decision makers have an obligation to avoid perpetuating injustice, our evolution of our model and data’s biases in attempts to expose the perpetuation of injustice keeps us in alignment with the middle view of fairness. \n",
    "\n",
    "Under the broad view of fairness, since the comparison focuses on the degree to which society overall is structured to allow people of similar ability and ambition to achieve similar success and attributes outcomes to whether they possess different ability or ambition, the fact that we were able to find clear differences in risk scores for differing groups of demographics, suggests that society is not structured to allow people people of similar ability and ambition to achieve similar success. Such as people from less-wealthy neighborhoods having a significant double the risk score of their wealthier counterparts, or men being two times as likely to get cancer than their female counterparts. Our models results suggest that these groups do not experience fair equality in some way, with these disproportionate affects of diseases suggesting that environmental or systemic factors may be at play. Intervention and change are needed at the basic level of societal structure, in this case we ideally would find that there are not environmental or societal impacts on the risk of different people contracting different diseases, seeing similar risk scores for differing peoples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Note: The additions/deletions on Github look skewed because of the creations/deletions of the csv files, not the actual code.\n",
    "\n",
    "Lindsey:\n",
    "At the beginning of the project, I worked alongside Sophie to clean the data and figure out how to merge our information without the kernel dying. This included pivoted columns, filtering the data into various conditions, and merging the datasets. The next large role I took on was creating the code to train models on the dataframes we had created in our DataCleaning file. Together, the three of us worked to create code to evaluate the models based on race, gender, ethnicity, birthplace, and current address. I took a leading role in figuring out how to evaluate birthplace risk based on wealth of cities in Massachusetts. I also worked to re-organize this evaluation code so that we could reuse it for all of the conditions we studied. In terms of the blog post writing, I completed the two discussion sections. Although our attention was divided among various aspects of the project, we collaborated effectively as a team, supporting one another whenever any member encountered a challenge.\n",
    "\n",
    "Julia: \n",
    "In the beginning of the project, I created data visualizations allowing us to better understand our data and project question goals. The large role I took on was to create code to evaluate the models based on race, gender, ethnicity, birthplace, and current address. I implemented the evaluation of cancer, heart diseases, and lung diseases. I worked alongside with Lindsey to find and import our Massachusetts wealth information, in order to evaluate birthplace and current town residence risk based on wealth.  \n",
    "I additionally went through our model code and repaired seeding and randomness issues, to ensure our models were performing to the same caliber and ‘accuracy’ across our code. Throughout the project, I took on the role of keeping our data thoroughly cleaned and organized, as we frequently found ourselves with extraneous and additional code we did not need, as well as a need to organize our code for comprehensibility and readability as we worked both separably and together. In terms of the blog post writing, I completed our Values Statement, Material & Methods section, as well as the discussion on the three views of fairness. Our efforts were comprehensive and collaborative throughout this project. Pair-programming was utilized alongside our individual divide-and-conquer. We functioned cohesively as a group, completing our project with an happy divide of labor and effort. \n",
    "\n",
    "Sophie: \n",
    "Lindsey and I started by working on cleaning and merging our data into usable (i.e. not large enough to crash  our kernel every time) datasets for model training. Afterwards, I contributed to the exploratory data analysis document by creating graphs showing differences in condition prevelance by race, ethnicity, and birthplace (for which I had to find the populations of each town in our dataset to calculate prevelance). We worked together on writing the code to generate models and risk scores for our conditions. I started to address the problem of random seeding in our data, which was causing variable results each time we ran, which Julia took on later. Afterwards I focused on the organization aspect of our blog post, writing explanatory comments for all our documents/code lines, and creating the format for our post in terms of linking all of our various working documents together into this one, more streamlined document. I also wrote our introduction and results section, and Julia and I worked together on our values statement, and I wrote parts of our approach. Overall, I think we worked very well as a group in terms of division of labor and coding together. We were all proactive in taking the lead on certain aspects of the project, and worked very collaboratively together when we were stuck on certain parts.\n",
    " \n",
    "\n",
    "\n",
    "In your group contributions statement, please include a short paragraph for each group member describing how they contributed to the project:\n",
    "\n",
    "Who worked on which parts of the source code?\n",
    "Who performed or visualized which experiments?\n",
    "Who led the writing of which parts of the blog post?\n",
    "Etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
