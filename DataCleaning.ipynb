{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergies = pd.read_csv('allergies.csv')\n",
    "careplans = pd.read_csv('careplans.csv')\n",
    "conditions = pd.read_csv('conditions.csv')\n",
    "encounters = pd.read_csv('encounters.csv') ##NOT USING RN, DO WE NEED?\n",
    "immunizations = pd.read_csv('immunizations.csv')\n",
    "medications = pd.read_csv('medications.csv')\n",
    "observations = pd.read_csv('observations.csv')\n",
    "patients = pd.read_csv('patients.csv')\n",
    "procedures = pd.read_csv('procedures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up dataframes: have one row per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALLERGIES\n",
    "allergies_pivot = pd.get_dummies(allergies['DESCRIPTION'])\n",
    "allergies_pivot['PATIENT'] = allergies['PATIENT']\n",
    "allergies_pivot = allergies_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CAREPLANS\n",
    "careplans_pivot = pd.get_dummies(careplans['DESCRIPTION'])\n",
    "careplans_pivot['PATIENT'] = careplans['PATIENT']\n",
    "careplans_pivot = careplans_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONDITIONS\n",
    "conditions_pivot = pd.get_dummies(conditions['DESCRIPTION'])\n",
    "conditions_pivot['PATIENT'] = conditions['PATIENT']\n",
    "conditions_pivot = conditions_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMMUNIZATIONS\n",
    "immunizations_pivot = pd.get_dummies(immunizations['DESCRIPTION'])\n",
    "immunizations_pivot['PATIENT'] = immunizations['PATIENT']\n",
    "immunizations_pivot = immunizations_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MEDICATIONS\n",
    "medications_pivot = pd.get_dummies(medications['DESCRIPTION'])\n",
    "medications_pivot['PATIENT'] = medications['PATIENT']\n",
    "medications_pivot = medications_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OBSERVATIONS\n",
    "observations['VALUE'] = pd.to_numeric(observations['VALUE'], errors='coerce')\n",
    "\n",
    "# Pivot table with mean aggregation\n",
    "observations_pivot= observations.pivot_table(index=observations.index, columns='DESCRIPTION', values='VALUE', fill_value=0, aggfunc='mean')\n",
    "observations_pivot['PATIENT'] = observations['PATIENT']\n",
    "observations_pivot = observations_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PROCEDURES\n",
    "procedures_pivot = pd.get_dummies(procedures['DESCRIPTION'])\n",
    "procedures_pivot['PATIENT'] = procedures['PATIENT']\n",
    "procedures_pivot = procedures_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add suffixes to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = patients.rename(columns={'patient': 'PATIENT'})\n",
    "\n",
    "def add_suffix(df, suffix):\n",
    "    renamed_columns = {}\n",
    "    for col_name in df.columns:\n",
    "        if col_name != 'PATIENT':\n",
    "            renamed_columns[col_name] = col_name + '_' + suffix\n",
    "        else:\n",
    "            renamed_columns[col_name] = col_name\n",
    "    return df.rename(columns=renamed_columns)\n",
    "\n",
    "\n",
    "allergies_clean = add_suffix(allergies_pivot, 'ALLERGIES')\n",
    "careplans_clean = add_suffix(careplans_pivot, 'CAREPLANS')\n",
    "conditions_clean = add_suffix(conditions_pivot, 'CONDITIONS')\n",
    "immunizations_clean = add_suffix(immunizations_pivot, 'IMMUNIZATIONS')\n",
    "medications_clean = add_suffix(medications_pivot, 'MEDICATIONS')\n",
    "observations_pivot = add_suffix(observations_pivot, 'OBSERVATIONS')\n",
    "procedures_clean = add_suffix(procedures_pivot, 'PROCEDURES')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split up encounters to add stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_rows = len(encounters_clean)\n",
    "# rows_per_section = total_rows // 8\n",
    "\n",
    "# section1 = encounters_clean.iloc[:rows_per_section]\n",
    "# section2 = encounters_clean.iloc[rows_per_section:2*rows_per_section]\n",
    "# section3 = encounters_clean.iloc[2*rows_per_section:3*rows_per_section]\n",
    "# section4 = encounters_clean.iloc[3*rows_per_section:4*rows_per_section]\n",
    "# section5 = encounters_clean.iloc[4*rows_per_section:5*rows_per_section]\n",
    "# section6 = encounters_clean.iloc[5*rows_per_section:6*rows_per_section]\n",
    "# section7 = encounters_clean.iloc[6*rows_per_section:7*rows_per_section]\n",
    "# section8 = encounters_clean.iloc[7*rows_per_section:]\n",
    "\n",
    "# section1 = add_suffix(section1, '1')\n",
    "# section2 = add_suffix(section2, '2')\n",
    "# section3 = add_suffix(section3, '3')\n",
    "# section4 = add_suffix(section4, '4')\n",
    "# section5 = add_suffix(section5, '5')\n",
    "# section6 = add_suffix(section6, '6')\n",
    "# section7 = add_suffix(section7, '7')\n",
    "# section8 = add_suffix(section8, '8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(conditions_spec):\n",
    "    \n",
    "    merged_df = pd.merge(conditions_spec, patients, on='PATIENT', how='left')\n",
    "    \n",
    "    # # Check if there are any matched patient IDs\n",
    "    # if not merged_df.empty:\n",
    "    #     print(\"Matched patient IDs found.\")\n",
    "    #     # Optionally, print or inspect the matched patient IDs\n",
    "    #     print(\"Matched patient IDs:\", merged_df['PATIENT'].unique())\n",
    "    # else:\n",
    "    #     print(\"No matched patient IDs found.\")\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, allergies_clean, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, careplans_clean, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, procedures_clean, on='PATIENT', how='left')\n",
    "    \n",
    "    # # Check if there are any matched patient IDs\n",
    "    # if not merged_df.empty:\n",
    "    #     print(\"2 Matched patient IDs found.\")\n",
    "    #     # Optionally, print or inspect the matched patient IDs\n",
    "    #     print(\"2 Matched patient IDs:\", merged_df['PATIENT'].unique())\n",
    "    # else:\n",
    "    #     print(\"2 No matched patient IDs found.\")\n",
    "    \n",
    "    # print(\"onto encounter merges\")\n",
    "    \n",
    "    # merged_df = pd.merge(merged_df, section1, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section2, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section3, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section4, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section5, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section6, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section7, on='PATIENT', how='left')\n",
    "    \n",
    "    print(\"3 merges left to go\")\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, immunizations_clean, on='PATIENT', how='left')\n",
    "    \n",
    "    print(\"1\")\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, medications_clean, on='PATIENT', how='left')\n",
    "    print(\"2\")\n",
    "\n",
    "    merged_df = pd.merge(merged_df, observations_pivot, on='PATIENT', how='left')\n",
    "    print(\"3\")\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate conditions dataframe based on disease (now just with diabetes but ultimately need to do with each disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 merges left to go\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "## DIABETES\n",
    "illness_descriptions = ['Diabetes','Prediabetes','Diabetic retinopathy associated with type II diabetes mellitus (disorder)', \n",
    "                        'Nonproliferative diabetic retinopathy due to type 2 diabetes mellitus (disorder)', 'Macular edema and retinopathy due to type 2 diabetes mellitus (disorder)', \n",
    "                        'Microalbuminuria due to type 2 diabetes mellitus (disorder)', 'Diabetic renal disease (disorder)', 'Neuropathy due to type 2 diabetes mellitus (disorder)']\n",
    "\n",
    "conditions_spec = pd.DataFrame()\n",
    "\n",
    "# Loop through each illness description and filter the DataFrame\n",
    "for description in illness_descriptions:\n",
    "    full_description = description + \"_CONDITIONS\"\n",
    "    \n",
    "    conditions_spec = pd.concat([conditions_spec, conditions_clean[conditions_clean[full_description] == 1]])\n",
    "\n",
    "# Drop duplicate rows if needed\n",
    "conditions_spec = conditions_spec.drop_duplicates()\n",
    "\n",
    "diabetes_df = merge_datasets(conditions_spec)\n",
    "diabetes_df.to_csv('diabetes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 merges left to go\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "## PREGNANCY\n",
    "illness_descriptions = ['Miscarriage in first trimester','Prediabetes','Miscarriage in second trimester',\n",
    "                        'Complication occuring during pregnancy','Preeclampsia', 'Antepartum eclampsia',\n",
    "                        'Tubal pregnancy', 'Congenital uterine anomaly', 'Blighted ovum']\n",
    "\n",
    "conditions_spec = pd.DataFrame()\n",
    "\n",
    "# Loop through each illness description and filter the DataFrame\n",
    "for description in illness_descriptions:\n",
    "    full_description = description + \"_CONDITIONS\"\n",
    "    \n",
    "    conditions_spec = pd.concat([conditions_spec, conditions_clean[conditions_clean[full_description] == 1]])\n",
    "\n",
    "# Drop duplicate rows if needed\n",
    "conditions_spec = conditions_spec.drop_duplicates()\n",
    "\n",
    "pregnancy_df = merge_datasets(conditions_spec)\n",
    "pregnancy_df.to_csv('pregnancy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 merges left to go\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "## CANCER\n",
    "illness_descriptions = ['Non-small cell lung cancer (disorder)', 'Non-small cell carcinoma of lung  TNM stage 4 (disorder)',\n",
    "                        'Primary small cell malignant neoplasm of lung  TNM stage 4 (disorder)','Non-small cell carcinoma of lung  TNM stage 2 (disorder)',\n",
    "                        'Non-small cell lung cancer (disorder)', 'Suspected lung cancer (situation)', 'Malignant tumor of colon',\n",
    "                        'Overlapping malignant neoplasm of colon']\n",
    "\n",
    "conditions_spec = pd.DataFrame()\n",
    "\n",
    "# Loop through each illness description and filter the DataFrame\n",
    "for description in illness_descriptions:\n",
    "    full_description = description + \"_CONDITIONS\"\n",
    "    \n",
    "    conditions_spec = pd.concat([conditions_spec, conditions_clean[conditions_clean[full_description] == 1]])\n",
    "\n",
    "# Drop duplicate rows if needed\n",
    "conditions_spec = conditions_spec.drop_duplicates()\n",
    "\n",
    "cancer_df = merge_datasets(conditions_spec)\n",
    "cancer_df.to_csv('cancer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 merges left to go\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "## HEART\n",
    "illness_descriptions = ['Coronary Heart Disease', 'History of cardiac arrest (situation)', 'Cardiac Arrest',\n",
    "                        'History of myocardial infarction (situation)', 'Myocardial Infarction']\n",
    "\n",
    "conditions_spec = pd.DataFrame()\n",
    "\n",
    "# Loop through each illness description and filter the DataFrame\n",
    "for description in illness_descriptions:\n",
    "    full_description = description + \"_CONDITIONS\"\n",
    "    \n",
    "    conditions_spec = pd.concat([conditions_spec, conditions_clean[conditions_clean[full_description] == 1]])\n",
    "\n",
    "# Drop duplicate rows if needed\n",
    "conditions_spec = conditions_spec.drop_duplicates()\n",
    "\n",
    "heart_df = merge_datasets(conditions_spec)\n",
    "heart_df.to_csv('heart.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we separate these in ETC to unique dataframes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 merges left to go\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "## ETC\n",
    "illness_descriptions = ['Hypertension', 'Stroke', 'Child attention deficit disorder', 'Drug overdose']\n",
    "\n",
    "conditions_spec = pd.DataFrame()\n",
    "\n",
    "# Loop through each illness description and filter the DataFrame\n",
    "for description in illness_descriptions:\n",
    "    full_description = description + \"_CONDITIONS\"\n",
    "    \n",
    "    conditions_spec = pd.concat([conditions_spec, conditions_clean[conditions_clean[full_description] == 1]])\n",
    "\n",
    "# Drop duplicate rows if needed\n",
    "conditions_spec = conditions_spec.drop_duplicates()\n",
    "\n",
    "etc_df = merge_datasets(conditions_spec)\n",
    "\n",
    "etc_df.to_csv('etc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 merges left to go\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "## LUNGS\n",
    "illness_descriptions = ['Asthma', 'Pulmonary emphysema (disorder)', 'Seasonal allergic rhinitis', \n",
    "                        'Acute bronchitis (disorder)', 'Chronic obstructive bronchitis (disorder)',\n",
    "                        'Childhood asthma', 'Perennial allergic rhinitis with seasonal variation',\n",
    "                        'Perennial allergic rhinitis', 'Acute bacterial sinusitis (disorder)', 'Chronic sinusitis (disorder)',\n",
    "                        'Sinusitis (disorder)']\n",
    "\n",
    "conditions_spec = pd.DataFrame()\n",
    "\n",
    "# Loop through each illness description and filter the DataFrame\n",
    "for description in illness_descriptions:\n",
    "    full_description = description + \"_CONDITIONS\"\n",
    "    \n",
    "    conditions_spec = pd.concat([conditions_spec, conditions_clean[conditions_clean[full_description] == 1]])\n",
    "\n",
    "# Drop duplicate rows if needed\n",
    "conditions_spec = conditions_spec.drop_duplicates()\n",
    "\n",
    "lungs_df = merge_datasets(conditions_spec)\n",
    "\n",
    "lungs_df.to_csv('lungs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unnecessary notes at bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate data usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get memory usage of each column\n",
    "# memory_usage_per_column = merged_df.memory_usage(deep=True)\n",
    "\n",
    "# # Sum up memory usage of all columns\n",
    "# total_memory_usage = memory_usage_per_column.sum()\n",
    "\n",
    "# print(\"Total memory usage of DataFrame: {} bytes\".format(total_memory_usage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES FROM PHIL TO STOP KERNEL DEATH\n",
    "Size of indiv. dataframes\n",
    "- delete columns that we are not going to use before we merge\n",
    "\n",
    "- read in datasets a chunk at a time\n",
    "    - operate on sequential parts of the data\n",
    "\n",
    "- if its still an issue, could get set up on cluster to compute there as well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
