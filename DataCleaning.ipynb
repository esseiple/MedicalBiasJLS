{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergies = pd.read_csv('allergies.csv')\n",
    "careplans = pd.read_csv('careplans.csv')\n",
    "claims = pd.read_csv('claims.csv')\n",
    "conditions = pd.read_csv('conditions.csv')\n",
    "encounters = pd.read_csv('encounters.csv')\n",
    "immunizations = pd.read_csv('immunizations.csv')\n",
    "medications = pd.read_csv('medications.csv')\n",
    "observations = pd.read_csv('observations.csv')\n",
    "patients = pd.read_csv('patients.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of indiv. dataframes\n",
    "- delete columns that we are not going to use before we merge\n",
    "\n",
    "- read in datasets a chunk at a time\n",
    "    - operate on sequential parts of the data\n",
    "\n",
    "- if its still an issue, could get set up on cluster to compute there as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['START','STOP']\n",
    "allergies_clean = allergies.drop(column_names, axis=1)\n",
    "careplans_clean = careplans.drop(column_names, axis=1)\n",
    "conditions_clean = conditions.drop(column_names, axis=1)\n",
    "medications_clean = medications.drop(column_names, axis=1)\n",
    "\n",
    "# Drop unnecessary patient information\n",
    "patients = patients.drop('ssn', axis=1)\n",
    "patients = patients.drop('passport', axis=1)\n",
    "patients = patients.drop('first', axis=1)\n",
    "patients = patients.drop('last', axis=1)\n",
    "patients = patients.drop('maiden', axis=1)\n",
    "patients = patients.drop('suffix', axis=1)\n",
    "patients = patients.drop('prefix', axis=1)\n",
    "## Do we need address/birthplace? could be geographically interesting ig?\n",
    "patients = patients.drop('drivers', axis=1) ## WHAT IS DRIVERS? don't think we need but do more research to make sure\n",
    "\n",
    "# drop diagnosis from claims as all entries are empty\n",
    "claims = claims.drop('DIAGNOSIS', axis=1)\n",
    "claims = claims.drop('ORGANIZATION', axis=1) # deleted this as all organizations are temp organizations\n",
    "\n",
    "column_names = ['DATE']\n",
    "observations_clean = observations.drop(column_names, axis=1)\n",
    "immunizations_clean = immunizations.drop(column_names, axis=1)\n",
    "encounters_clean = encounters.drop(column_names, axis=1)\n",
    "\n",
    "## should we remove descriptions as we will prob use codes to train model and descriptions only as a way to understand the model's output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = patients.rename(columns={'patient': 'PATIENT'})\n",
    "\n",
    "def add_suffix(df, suffix):\n",
    "    renamed_columns = {}\n",
    "    for col_name in df.columns:\n",
    "        if col_name != 'PATIENT':\n",
    "            renamed_columns[col_name] = col_name + '_' + suffix\n",
    "        else:\n",
    "            renamed_columns[col_name] = col_name\n",
    "    return df.rename(columns=renamed_columns)\n",
    "\n",
    "\n",
    "allergies_clean = add_suffix(allergies_clean, 'ALLERGIES')\n",
    "careplans_clean = add_suffix(careplans_clean, 'CAREPLANS')\n",
    "claims_clean = add_suffix(claims, 'CLAIMS')\n",
    "conditions_clean = add_suffix(conditions_clean, 'CONDITIONS')\n",
    "encounters_clean = add_suffix(encounters_clean, 'ENCOUNTERS')\n",
    "immunizations_clean = add_suffix(immunizations_clean, 'IMMUNIZATIONS')\n",
    "medications_clean = add_suffix(medications_clean, 'MEDICATIONS')\n",
    "observations_clean = add_suffix(observations_clean, 'OBSERVATIONS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(allergies_clean, patients, on='PATIENT', how='outer')\n",
    "merged_df = pd.merge(merged_df, careplans_clean, on='PATIENT', how='outer')\n",
    "\n",
    "# merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, claims_clean, on='PATIENT', how='outer')\n",
    "merged_df = pd.merge(merged_df, conditions_clean, on='PATIENT', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df = pd.merge(merged_df, encounters_clean, on='PATIENT', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(encounters_clean)\n",
    "rows_per_section = total_rows // 8\n",
    "\n",
    "section1 = encounters_clean.iloc[:rows_per_section]\n",
    "section2 = encounters_clean.iloc[rows_per_section:2*rows_per_section]\n",
    "section3 = encounters_clean.iloc[2*rows_per_section:3*rows_per_section]\n",
    "section4 = encounters_clean.iloc[3*rows_per_section:4*rows_per_section]\n",
    "section5 = encounters_clean.iloc[4*rows_per_section:5*rows_per_section]\n",
    "section6 = encounters_clean.iloc[5*rows_per_section:6*rows_per_section]\n",
    "section7 = encounters_clean.iloc[6*rows_per_section:7*rows_per_section]\n",
    "section8 = encounters_clean.iloc[7*rows_per_section:]\n",
    "\n",
    "# print(section1.size)\n",
    "# print(section2.size)\n",
    "# print(section3.size)\n",
    "# print(section4.size)\n",
    "# print(section5.size)\n",
    "# print(section6.size)\n",
    "# print(section7.size)\n",
    "# print(section8.size)\n",
    "# print(total_rows)\n",
    "\n",
    "section1 = add_suffix(section1, '1')\n",
    "section2 = add_suffix(section2, '2')\n",
    "section3 = add_suffix(section3, '3')\n",
    "section4 = add_suffix(section4, '4')\n",
    "section5 = add_suffix(section5, '5')\n",
    "section6 = add_suffix(section6, '6')\n",
    "section7 = add_suffix(section7, '7')\n",
    "section8 = add_suffix(section8, '8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, section1, on='PATIENT', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, section2, on='PATIENT', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section3[\"PATIENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, section3, on='PATIENT', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(merged_df, section4, on='PATIENT', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, section5, on='PATIENT', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, section6, on='PATIENT', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, section7, on='PATIENT', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, section8, on='PATIENT', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(final_merged_df, immunizations_clean, on='PATIENT', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(merged_df, medications_clean, on='PATIENT', how='outer')\n",
    "merged_df = pd.merge(merged_df, observations_clean, on='PATIENT', how='outer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
