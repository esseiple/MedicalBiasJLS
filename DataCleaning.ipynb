{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergies = pd.read_csv('allergies.csv')\n",
    "careplans = pd.read_csv('careplans.csv')\n",
    "# claims = pd.read_csv('claims.csv')\n",
    "conditions = pd.read_csv('conditions.csv')\n",
    "encounters = pd.read_csv('encounters.csv')\n",
    "immunizations = pd.read_csv('immunizations.csv')\n",
    "medications = pd.read_csv('medications.csv')\n",
    "observations = pd.read_csv('observations.csv')\n",
    "patients = pd.read_csv('patients.csv')\n",
    "procedures = pd.read_csv('procedures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['START','STOP']\n",
    "allergies_clean = allergies.drop(column_names, axis=1)\n",
    "careplans_clean = careplans.drop(column_names, axis=1)\n",
    "conditions_clean = conditions.drop(column_names, axis=1)\n",
    "medications_clean = medications.drop(column_names, axis=1)\n",
    "\n",
    "# Drop unnecessary patient information\n",
    "patients = patients.drop('ssn', axis=1)\n",
    "patients = patients.drop('passport', axis=1)\n",
    "patients = patients.drop('first', axis=1)\n",
    "patients = patients.drop('last', axis=1)\n",
    "patients = patients.drop('maiden', axis=1)\n",
    "patients = patients.drop('suffix', axis=1)\n",
    "patients = patients.drop('prefix', axis=1)\n",
    "## Do we need address/birthplace? could be geographically interesting ig?\n",
    "patients = patients.drop('drivers', axis=1) ## WHAT IS DRIVERS? don't think we need but do more research to make sure\n",
    "\n",
    "# drop diagnosis from claims as all entries are empty\n",
    "# claims = claims.drop('DIAGNOSIS', axis=1)\n",
    "# claims = claims.drop('ORGANIZATION', axis=1) # deleted this as all organizations are temp organizations\n",
    "\n",
    "column_names = ['DATE']\n",
    "observations_clean = observations.drop(column_names, axis=1)\n",
    "immunizations_clean = immunizations.drop(column_names, axis=1)\n",
    "encounters_clean = encounters.drop(column_names, axis=1)\n",
    "\n",
    "column_names = ['DESCRIPTION']\n",
    "conditions_clean = conditions_clean.drop(column_names, axis=1)\n",
    "encounters_clean = encounters_clean.drop(column_names, axis=1)\n",
    "immunizations_clean = immunizations_clean.drop(column_names, axis=1)\n",
    "observations_clean = observations_clean.drop(column_names, axis=1)\n",
    "medications_clean = medications_clean.drop(column_names, axis=1)\n",
    "procedures_clean = procedures.drop(column_names, axis=1)\n",
    "\n",
    "\n",
    "medications_clean = medications_clean.drop('REASONDESCRIPTION', axis=1)\n",
    "procedures_clean = procedures_clean.drop('REASONDESCRIPTION', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add suffixes to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = patients.rename(columns={'patient': 'PATIENT'})\n",
    "\n",
    "def add_suffix(df, suffix):\n",
    "    renamed_columns = {}\n",
    "    for col_name in df.columns:\n",
    "        if col_name != 'PATIENT':\n",
    "            renamed_columns[col_name] = col_name + '_' + suffix\n",
    "        else:\n",
    "            renamed_columns[col_name] = col_name\n",
    "    return df.rename(columns=renamed_columns)\n",
    "\n",
    "\n",
    "allergies_clean = add_suffix(allergies_clean, 'ALLERGIES')\n",
    "careplans_clean = add_suffix(careplans_clean, 'CAREPLANS')\n",
    "# claims_clean = add_suffix(claims, 'CLAIMS')\n",
    "conditions_clean = add_suffix(conditions_clean, 'CONDITIONS')\n",
    "encounters_clean = add_suffix(encounters_clean, 'ENCOUNTERS')\n",
    "immunizations_clean = add_suffix(immunizations_clean, 'IMMUNIZATIONS')\n",
    "medications_clean = add_suffix(medications_clean, 'MEDICATIONS')\n",
    "observations_clean = add_suffix(observations_clean, 'OBSERVATIONS')\n",
    "procedures_clean = add_suffix(procedures_clean, 'PROCEDURES')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split up encounters to add stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(encounters_clean)\n",
    "rows_per_section = total_rows // 8\n",
    "\n",
    "section1 = encounters_clean.iloc[:rows_per_section]\n",
    "section2 = encounters_clean.iloc[rows_per_section:2*rows_per_section]\n",
    "section3 = encounters_clean.iloc[2*rows_per_section:3*rows_per_section]\n",
    "section4 = encounters_clean.iloc[3*rows_per_section:4*rows_per_section]\n",
    "section5 = encounters_clean.iloc[4*rows_per_section:5*rows_per_section]\n",
    "section6 = encounters_clean.iloc[5*rows_per_section:6*rows_per_section]\n",
    "section7 = encounters_clean.iloc[6*rows_per_section:7*rows_per_section]\n",
    "section8 = encounters_clean.iloc[7*rows_per_section:]\n",
    "\n",
    "section1 = add_suffix(section1, '1')\n",
    "section2 = add_suffix(section2, '2')\n",
    "section3 = add_suffix(section3, '3')\n",
    "section4 = add_suffix(section4, '4')\n",
    "section5 = add_suffix(section5, '5')\n",
    "section6 = add_suffix(section6, '6')\n",
    "section7 = add_suffix(section7, '7')\n",
    "section8 = add_suffix(section8, '8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets():\n",
    "    \n",
    "    merged_df = pd.merge(allergies_clean, patients, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, careplans_clean, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, conditions_clean, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, procedures_clean, on='PATIENT', how='left')\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, section1, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, section2, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, section3, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, section4, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, section5, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, section6, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, section7, on='PATIENT', how='left')\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, immunizations_clean, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, medications_clean, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, observations_clean, on='PATIENT', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate data based on disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate data usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory usage of DataFrame: 20279191894 bytes\n"
     ]
    }
   ],
   "source": [
    "# # Get memory usage of each column\n",
    "# memory_usage_per_column = merged_df.memory_usage(deep=True)\n",
    "\n",
    "# # Sum up memory usage of all columns\n",
    "# total_memory_usage = memory_usage_per_column.sum()\n",
    "\n",
    "# print(\"Total memory usage of DataFrame: {} bytes\".format(total_memory_usage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES FROM PHIL TO STOP KERNEL DEATH\n",
    "Size of indiv. dataframes\n",
    "- delete columns that we are not going to use before we merge\n",
    "\n",
    "- read in datasets a chunk at a time\n",
    "    - operate on sequential parts of the data\n",
    "\n",
    "- if its still an issue, could get set up on cluster to compute there as well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
