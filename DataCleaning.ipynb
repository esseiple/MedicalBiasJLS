{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergies = pd.read_csv('allergies.csv')\n",
    "careplans = pd.read_csv('careplans.csv')\n",
    "conditions = pd.read_csv('conditions.csv')\n",
    "encounters = pd.read_csv('encounters.csv') ##NOT USING RN, DO WE NEED?\n",
    "immunizations = pd.read_csv('immunizations.csv')\n",
    "medications = pd.read_csv('medications.csv')\n",
    "observations = pd.read_csv('observations.csv')\n",
    "patients = pd.read_csv('patients.csv')\n",
    "procedures = pd.read_csv('procedures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up dataframes: have one row per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALLERGIES\n",
    "allergies_pivot = pd.get_dummies(allergies['DESCRIPTION'])\n",
    "allergies_pivot['PATIENT'] = allergies['PATIENT']\n",
    "allergies_pivot = allergies_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CAREPLANS\n",
    "careplans_pivot = pd.get_dummies(careplans['DESCRIPTION'])\n",
    "careplans_pivot['PATIENT'] = careplans['PATIENT']\n",
    "careplans_pivot = careplans_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONDITIONS\n",
    "conditions_pivot = pd.get_dummies(conditions['DESCRIPTION'])\n",
    "conditions_pivot['PATIENT'] = conditions['PATIENT']\n",
    "conditions_pivot = conditions_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMMUNIZATIONS\n",
    "immunizations_pivot = pd.get_dummies(immunizations['DESCRIPTION'])\n",
    "immunizations_pivot['PATIENT'] = immunizations['PATIENT']\n",
    "immunizations_pivot = immunizations_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MEDICATIONS\n",
    "medications_pivot = pd.get_dummies(medications['DESCRIPTION'])\n",
    "medications_pivot['PATIENT'] = medications['PATIENT']\n",
    "medications_pivot = medications_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OBSERVATIONS\n",
    "observations['VALUE'] = pd.to_numeric(observations['VALUE'], errors='coerce')\n",
    "\n",
    "# Pivot table with mean aggregation\n",
    "observations_pivot= observations.pivot_table(index=observations.index, columns='DESCRIPTION', values='VALUE', fill_value=0, aggfunc='mean')\n",
    "observations_pivot['PATIENT'] = observations['PATIENT']\n",
    "observations_pivot = observations_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PROCEDURES\n",
    "procedures_pivot = pd.get_dummies(procedures['DESCRIPTION'])\n",
    "procedures_pivot['PATIENT'] = procedures['PATIENT']\n",
    "procedures_pivot = procedures_pivot.groupby('PATIENT').sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add suffixes to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = patients.rename(columns={'patient': 'PATIENT'})\n",
    "\n",
    "def add_suffix(df, suffix):\n",
    "    renamed_columns = {}\n",
    "    for col_name in df.columns:\n",
    "        if col_name != 'PATIENT':\n",
    "            renamed_columns[col_name] = col_name + '_' + suffix\n",
    "        else:\n",
    "            renamed_columns[col_name] = col_name\n",
    "    return df.rename(columns=renamed_columns)\n",
    "\n",
    "\n",
    "allergies_clean = add_suffix(allergies_pivot, 'ALLERGIES')\n",
    "careplans_clean = add_suffix(careplans_pivot, 'CAREPLANS')\n",
    "conditions_clean = add_suffix(conditions_pivot, 'CONDITIONS')\n",
    "immunizations_clean = add_suffix(immunizations_pivot, 'IMMUNIZATIONS')\n",
    "medications_clean = add_suffix(medications_pivot, 'MEDICATIONS')\n",
    "observations_pivot = add_suffix(observations_pivot, 'OBSERVATIONS')\n",
    "procedures_clean = add_suffix(procedures_pivot, 'PROCEDURES')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split up encounters to add stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_rows = len(encounters_clean)\n",
    "# rows_per_section = total_rows // 8\n",
    "\n",
    "# section1 = encounters_clean.iloc[:rows_per_section]\n",
    "# section2 = encounters_clean.iloc[rows_per_section:2*rows_per_section]\n",
    "# section3 = encounters_clean.iloc[2*rows_per_section:3*rows_per_section]\n",
    "# section4 = encounters_clean.iloc[3*rows_per_section:4*rows_per_section]\n",
    "# section5 = encounters_clean.iloc[4*rows_per_section:5*rows_per_section]\n",
    "# section6 = encounters_clean.iloc[5*rows_per_section:6*rows_per_section]\n",
    "# section7 = encounters_clean.iloc[6*rows_per_section:7*rows_per_section]\n",
    "# section8 = encounters_clean.iloc[7*rows_per_section:]\n",
    "\n",
    "# section1 = add_suffix(section1, '1')\n",
    "# section2 = add_suffix(section2, '2')\n",
    "# section3 = add_suffix(section3, '3')\n",
    "# section4 = add_suffix(section4, '4')\n",
    "# section5 = add_suffix(section5, '5')\n",
    "# section6 = add_suffix(section6, '6')\n",
    "# section7 = add_suffix(section7, '7')\n",
    "# section8 = add_suffix(section8, '8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(conditions_spec):\n",
    "    \n",
    "    merged_df = pd.merge(conditions_spec, patients, on='PATIENT', how='left')\n",
    "    \n",
    "    # # Check if there are any matched patient IDs\n",
    "    # if not merged_df.empty:\n",
    "    #     print(\"Matched patient IDs found.\")\n",
    "    #     # Optionally, print or inspect the matched patient IDs\n",
    "    #     print(\"Matched patient IDs:\", merged_df['PATIENT'].unique())\n",
    "    # else:\n",
    "    #     print(\"No matched patient IDs found.\")\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, allergies_clean, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, careplans_clean, on='PATIENT', how='left')\n",
    "    merged_df = pd.merge(merged_df, procedures_clean, on='PATIENT', how='left')\n",
    "    \n",
    "    # # Check if there are any matched patient IDs\n",
    "    # if not merged_df.empty:\n",
    "    #     print(\"2 Matched patient IDs found.\")\n",
    "    #     # Optionally, print or inspect the matched patient IDs\n",
    "    #     print(\"2 Matched patient IDs:\", merged_df['PATIENT'].unique())\n",
    "    # else:\n",
    "    #     print(\"2 No matched patient IDs found.\")\n",
    "    \n",
    "    # print(\"onto encounter merges\")\n",
    "    \n",
    "    # merged_df = pd.merge(merged_df, section1, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section2, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section3, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section4, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section5, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section6, on='PATIENT', how='left')\n",
    "    # merged_df = pd.merge(merged_df, section7, on='PATIENT', how='left')\n",
    "    \n",
    "    print(\"3 merges left to go\")\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, immunizations_clean, on='PATIENT', how='left')\n",
    "    \n",
    "    print(\"1\")\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, medications_clean, on='PATIENT', how='left')\n",
    "    print(\"2\")\n",
    "\n",
    "    merged_df = pd.merge(merged_df, observations_pivot, on='PATIENT', how='left')\n",
    "    print(\"3\")\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate conditions dataframe based on disease (now just with diabetes but ultimately need to do with each disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illness_descriptions = ['Diabetes','Prediabetes']\n",
    "\n",
    "conditions_spec = pd.DataFrame()\n",
    "\n",
    "# Loop through each illness description and filter the DataFrame\n",
    "for description in illness_descriptions:\n",
    "    full_description = description + \"_CONDITIONS\"\n",
    "    \n",
    "    conditions_spec = pd.concat([conditions_spec, conditions_clean[conditions_clean[full_description] == 1]])\n",
    "\n",
    "# Drop duplicate rows if needed\n",
    "conditions_spec = conditions_spec.drop_duplicates()\n",
    "\n",
    "diabetes_df = merge_datasets(conditions_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unnecessary notes at bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate data usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get memory usage of each column\n",
    "# memory_usage_per_column = merged_df.memory_usage(deep=True)\n",
    "\n",
    "# # Sum up memory usage of all columns\n",
    "# total_memory_usage = memory_usage_per_column.sum()\n",
    "\n",
    "# print(\"Total memory usage of DataFrame: {} bytes\".format(total_memory_usage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES FROM PHIL TO STOP KERNEL DEATH\n",
    "Size of indiv. dataframes\n",
    "- delete columns that we are not going to use before we merge\n",
    "\n",
    "- read in datasets a chunk at a time\n",
    "    - operate on sequential parts of the data\n",
    "\n",
    "- if its still an issue, could get set up on cluster to compute there as well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
